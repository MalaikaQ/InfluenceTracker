{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53fa0ea",
   "metadata": {},
   "source": [
    "# Tracking Misogyny in Online Communities: A Longitudinal Analysis\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook analyzes the correlation between misogynistic language in online communities and the rise of red-pill influencers like Andrew Tate. \n",
    "\n",
    "### Core Research Questions:\n",
    "1. **Has misogynistic language in online communities increased over time?**\n",
    "2. **Is there a measurable spike in misogynistic content correlated with the rise of Andrew Tate and similar \"red-pilled\" influencers?**\n",
    "3. **Which types of communities (e.g., subreddit categories, YouTube channels) are most affected?**\n",
    "\n",
    "### Data Sources:\n",
    "- **Reddit**: Comments from various subreddits (r/MensRights, r/Incels, r/Feminism, r/Gaming, etc.)\n",
    "- **YouTube**: Comments from Andrew Tate and related influencer videos\n",
    "- **Cultural Timeline**: Key events and milestones for influencers\n",
    "\n",
    "### Methodology:\n",
    "1. Data Collection + Cleaning\n",
    "2. Misogyny Detection (Hybrid: Lexicon + ML)\n",
    "3. Time Series Analysis\n",
    "4. Community Comparison\n",
    "5. Event Correlation Analysis\n",
    "6. Visualization and Reporting\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3d5bc",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Define Utility Functions\n",
    "\n",
    "First, let's import all the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Text processing and NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Data collection APIs\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Add project modules to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root / 'src'))\n",
    "\n",
    "# Import our custom modules\n",
    "from utils.config import *\n",
    "from utils.text_processing import TextProcessor, create_misogyny_lexicon\n",
    "from data_collection.reddit_scraper import RedditScraper\n",
    "from data_collection.youtube_scraper import YouTubeScraper\n",
    "from data_collection.timeline_events import TimelineEvents, create_extended_timeline\n",
    "from analysis.misogyny_detector import MisogynyDetector, create_synthetic_training_data\n",
    "from analysis.time_series_analysis import TimeSeriesAnalyzer\n",
    "from visualization.plotting import MisogynyVisualizer\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìÅ Project root: {project_root}\")\n",
    "print(f\"üìä Analysis will be conducted from: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6905c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize key components\n",
    "text_processor = TextProcessor()\n",
    "timeline_events = create_extended_timeline()\n",
    "misogyny_detector = MisogynyDetector()\n",
    "time_series_analyzer = TimeSeriesAnalyzer()\n",
    "visualizer = MisogynyVisualizer()\n",
    "\n",
    "# Display configuration\n",
    "print(\"üîß Project Configuration:\")\n",
    "print(f\"   Reddit communities: {len(REDDIT_COMMUNITIES)} categories\")\n",
    "print(f\"   YouTube targets: {len(YOUTUBE_TARGETS)} categories\")\n",
    "print(f\"   Timeline events: {len(timeline_events.events)} events\")\n",
    "print(f\"   Analysis granularity: {ANALYSIS_SETTINGS['time_granularity']}\")\n",
    "print(f\"   Normalization method: {ANALYSIS_SETTINGS['normalization_method']}\")\n",
    "\n",
    "# Show sample target communities\n",
    "print(\"\\nüìã Sample Target Communities:\")\n",
    "for category, communities in list(REDDIT_COMMUNITIES.items())[:3]:\n",
    "    print(f\"   {category}: {communities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44619eb9",
   "metadata": {},
   "source": [
    "## 2. Data Collection: Reddit Comments\n",
    "\n",
    "We'll collect comments from various Reddit communities to analyze trends in misogynistic language. \n",
    "\n",
    "**Note**: For this demonstration, we'll use synthetic data. In a real implementation, you would:\n",
    "1. Set up Reddit API credentials\n",
    "2. Use the RedditScraper class to collect real data\n",
    "3. Handle rate limiting and API quotas\n",
    "\n",
    "### Target Communities:\n",
    "- **Men's Rights/Red-pill**: r/MensRights, r/TheRedPill, r/MGTOW\n",
    "- **Feminist**: r/Feminism, r/TwoXChromosomes\n",
    "- **General**: r/AskReddit, r/politics, r/gaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8610bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, create synthetic Reddit data\n",
    "def create_synthetic_reddit_data(n_comments=5000):\n",
    "    \"\"\"Create synthetic Reddit comments with realistic patterns.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Date range from 2020 to 2024\n",
    "    start_date = datetime.datetime(2020, 1, 1)\n",
    "    end_date = datetime.datetime(2024, 1, 1)\n",
    "    \n",
    "    # Generate random dates with more recent data\n",
    "    date_range = (end_date - start_date).days\n",
    "    random_days = np.random.exponential(scale=date_range/4, size=n_comments)\n",
    "    random_days = np.clip(random_days, 0, date_range)\n",
    "    dates = [end_date - datetime.timedelta(days=int(day)) for day in random_days]\n",
    "    \n",
    "    # Community distribution (more data from controversial communities)\n",
    "    communities = ['r/MensRights', 'r/TheRedPill', 'r/Feminism', 'r/TwoXChromosomes', \n",
    "                   'r/AskReddit', 'r/politics', 'r/gaming', 'r/relationship_advice']\n",
    "    community_weights = [0.2, 0.15, 0.1, 0.1, 0.2, 0.1, 0.1, 0.05]\n",
    "    \n",
    "    # Sample comments with varying likelihood of misogyny by community\n",
    "    misogyny_rates = {\n",
    "        'r/MensRights': 0.4, 'r/TheRedPill': 0.6, 'r/Feminism': 0.05, \n",
    "        'r/TwoXChromosomes': 0.02, 'r/AskReddit': 0.08, 'r/politics': 0.12,\n",
    "        'r/gaming': 0.15, 'r/relationship_advice': 0.1\n",
    "    }\n",
    "    \n",
    "    # Sample comment templates\n",
    "    neutral_comments = [\n",
    "        \"I think this is an interesting perspective on the topic.\",\n",
    "        \"Thanks for sharing your experience with this.\",\n",
    "        \"This article raises some important points about society.\",\n",
    "        \"I've been following this discussion for a while now.\",\n",
    "        \"What are your thoughts on this development?\",\n",
    "        \"This reminds me of a similar situation I encountered.\",\n",
    "        \"The data seems to support this conclusion.\",\n",
    "        \"I appreciate you taking the time to explain this.\",\n",
    "    ]\n",
    "    \n",
    "    misogynistic_comments = [\n",
    "        \"women are always playing the victim card these days\",\n",
    "        \"typical female behavior, can't take responsibility\",\n",
    "        \"she's probably just looking for attention like all of them\",\n",
    "        \"awalt - all women are like that, hypergamous by nature\",\n",
    "        \"women hit the wall at 30 and then wonder where all the good men went\",\n",
    "        \"feminism has destroyed traditional family values\",\n",
    "        \"she belongs in the kitchen, not in the workplace\",\n",
    "        \"women can't think logically, only emotionally\",\n",
    "        \"typical feminist propaganda trying to shame men\",\n",
    "        \"women only want alpha chads until they need beta bux\",\n",
    "    ]\n",
    "    \n",
    "    synthetic_data = []\n",
    "    \n",
    "    for i in range(n_comments):\n",
    "        # Select community\n",
    "        community = np.random.choice(communities, p=community_weights)\n",
    "        \n",
    "        # Determine if comment is misogynistic based on community\n",
    "        is_misogynistic = np.random.random() < misogyny_rates[community]\n",
    "        \n",
    "        # Select comment text\n",
    "        if is_misogynistic:\n",
    "            base_comment = np.random.choice(misogynistic_comments)\n",
    "            # Add some variation\n",
    "            variations = [\" honestly\", \" tbh\", \" imo\", \" just saying\", \" facts\"]\n",
    "            comment = base_comment + np.random.choice(variations + [\"\"])\n",
    "        else:\n",
    "            comment = np.random.choice(neutral_comments)\n",
    "        \n",
    "        # Add temporal trend (increasing misogyny over time, especially around events)\n",
    "        date = dates[i]\n",
    "        if date > datetime.datetime(2022, 6, 1):  # Around Andrew Tate's peak\n",
    "            if np.random.random() < 0.3:  # 30% chance to flip to misogynistic\n",
    "                if not is_misogynistic:\n",
    "                    comment = np.random.choice(misogynistic_comments)\n",
    "                    is_misogynistic = True\n",
    "        \n",
    "        synthetic_data.append({\n",
    "            'comment_id': f'comment_{i}',\n",
    "            'subreddit': community,\n",
    "            'author': f'user_{np.random.randint(1, 1000)}',\n",
    "            'body': comment,\n",
    "            'score': np.random.randint(-5, 100),\n",
    "            'created_utc': date,\n",
    "            'category': 'mens_rights' if community in ['r/MensRights', 'r/TheRedPill'] \n",
    "                       else 'feminist' if community in ['r/Feminism', 'r/TwoXChromosomes']\n",
    "                       else 'general',\n",
    "            'true_misogyny': is_misogynistic  # Ground truth for validation\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(synthetic_data)\n",
    "\n",
    "# Create synthetic data\n",
    "print(\"üîÑ Creating synthetic Reddit data...\")\n",
    "reddit_data = create_synthetic_reddit_data(5000)\n",
    "\n",
    "print(f\"‚úÖ Created {len(reddit_data)} synthetic Reddit comments\")\n",
    "print(f\"üìÖ Date range: {reddit_data['created_utc'].min()} to {reddit_data['created_utc'].max()}\")\n",
    "print(f\"üèõÔ∏è Communities: {reddit_data['subreddit'].unique()}\")\n",
    "print(f\"üìä True misogyny rate: {reddit_data['true_misogyny'].mean():.3f}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nüìã Sample Comments:\")\n",
    "reddit_data[['subreddit', 'body', 'true_misogyny', 'created_utc']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb4d751",
   "metadata": {},
   "source": [
    "## 3. Data Collection: YouTube Comments\n",
    "\n",
    "Next, we'll collect comments from YouTube videos by various influencers. We'll focus on:\n",
    "- **Red-pill influencers**: Andrew Tate, Fresh & Fit, Sneako\n",
    "- **Feminist creators**: ContraPoints, Lindsay Ellis (for contrast)\n",
    "- **Mainstream**: General content creators\n",
    "\n",
    "**Note**: This demonstration uses synthetic data. Real implementation would use the YouTube Data API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca6cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic YouTube data\n",
    "def create_synthetic_youtube_data(n_comments=3000):\n",
    "    \"\"\"Create synthetic YouTube comments.\"\"\"\n",
    "    np.random.seed(43)\n",
    "    \n",
    "    # Influencer categories with different misogyny rates\n",
    "    influencers = {\n",
    "        'Andrew Tate': {'category': 'red_pill', 'misogyny_rate': 0.7},\n",
    "        'Fresh & Fit': {'category': 'red_pill', 'misogyny_rate': 0.6},\n",
    "        'Sneako': {'category': 'red_pill', 'misogyny_rate': 0.55},\n",
    "        'ContraPoints': {'category': 'feminist', 'misogyny_rate': 0.05},\n",
    "        'Lindsay Ellis': {'category': 'feminist', 'misogyny_rate': 0.03},\n",
    "        'PewDiePie': {'category': 'mainstream', 'misogyny_rate': 0.12},\n",
    "        'MrBeast': {'category': 'mainstream', 'misogyny_rate': 0.08}\n",
    "    }\n",
    "    \n",
    "    # Generate dates with clustering around key events\n",
    "    start_date = datetime.datetime(2020, 1, 1)\n",
    "    end_date = datetime.datetime(2024, 1, 1)\n",
    "    \n",
    "    # Key event dates (increased activity)\n",
    "    event_dates = [\n",
    "        datetime.datetime(2022, 6, 15),  # Tate peak virality\n",
    "        datetime.datetime(2022, 8, 19),  # Tate ban\n",
    "        datetime.datetime(2022, 12, 29), # Tate arrest\n",
    "    ]\n",
    "    \n",
    "    synthetic_youtube_data = []\n",
    "    \n",
    "    for i in range(n_comments):\n",
    "        # Select influencer\n",
    "        influencer = np.random.choice(list(influencers.keys()))\n",
    "        influencer_data = influencers[influencer]\n",
    "        \n",
    "        # Generate date with clustering around events\n",
    "        if np.random.random() < 0.4:  # 40% around events\n",
    "            event_date = np.random.choice(event_dates)\n",
    "            days_offset = np.random.normal(0, 15)  # Within ~30 days of event\n",
    "            date = event_date + datetime.timedelta(days=days_offset)\n",
    "        else:\n",
    "            # Random date\n",
    "            random_days = np.random.randint(0, (end_date - start_date).days)\n",
    "            date = start_date + datetime.timedelta(days=random_days)\n",
    "        \n",
    "        # Clip date to valid range\n",
    "        date = max(start_date, min(end_date, date))\n",
    "        \n",
    "        # Determine if comment is misogynistic\n",
    "        is_misogynistic = np.random.random() < influencer_data['misogyny_rate']\n",
    "        \n",
    "        # Generate comment text\n",
    "        if is_misogynistic:\n",
    "            youtube_misogynistic_comments = [\n",
    "                \"women are destroying western civilization\",\n",
    "                \"tate is speaking facts about female nature\",\n",
    "                \"these feminist creators are just mad they hit the wall\",\n",
    "                \"women only care about money and status\",\n",
    "                \"typical female trying to shame successful men\",\n",
    "                \"she's just jealous of alpha males like tate\",\n",
    "                \"women need to learn their place in society\",\n",
    "                \"feminism is cancer, based andrew tate\",\n",
    "                \"all women are hypergamous gold diggers\",\n",
    "                \"this is why men are going their own way\"\n",
    "            ]\n",
    "            comment = np.random.choice(youtube_misogynistic_comments)\n",
    "        else:\n",
    "            youtube_neutral_comments = [\n",
    "                \"interesting perspective on modern society\",\n",
    "                \"thanks for the thoughtful analysis\",\n",
    "                \"this video really made me think\",\n",
    "                \"appreciate the balanced viewpoint\",\n",
    "                \"great content as always\",\n",
    "                \"well researched and presented\",\n",
    "                \"this is important information to know\",\n",
    "                \"love the production quality\"\n",
    "            ]\n",
    "            comment = np.random.choice(youtube_neutral_comments)\n",
    "        \n",
    "        synthetic_youtube_data.append({\n",
    "            'comment_id': f'yt_comment_{i}',\n",
    "            'video_id': f'video_{influencer.replace(\" \", \"_\").lower()}_{np.random.randint(1, 20)}',\n",
    "            'channel_title': influencer,\n",
    "            'author': f'yt_user_{np.random.randint(1, 500)}',\n",
    "            'text': comment,\n",
    "            'like_count': np.random.randint(0, 50),\n",
    "            'published_at': date,\n",
    "            'influencer_category': influencer_data['category'],\n",
    "            'true_misogyny': is_misogynistic\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(synthetic_youtube_data)\n",
    "\n",
    "# Create synthetic YouTube data\n",
    "print(\"üîÑ Creating synthetic YouTube data...\")\n",
    "youtube_data = create_synthetic_youtube_data(3000)\n",
    "\n",
    "print(f\"‚úÖ Created {len(youtube_data)} synthetic YouTube comments\")\n",
    "print(f\"üìÖ Date range: {youtube_data['published_at'].min()} to {youtube_data['published_at'].max()}\")\n",
    "print(f\"üì∫ Channels: {youtube_data['channel_title'].unique()}\")\n",
    "print(f\"üìä True misogyny rate: {youtube_data['true_misogyny'].mean():.3f}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nüìã Sample YouTube Comments:\")\n",
    "youtube_data[['channel_title', 'text', 'true_misogyny', 'published_at']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15846f24",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning and Preprocessing\n",
    "\n",
    "Now we'll clean and preprocess our text data to prepare it for analysis. This involves:\n",
    "- Removing duplicates and invalid entries\n",
    "- Filtering by text length\n",
    "- Standardizing date formats\n",
    "- Basic text cleaning (while preserving important terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b7579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess the data\n",
    "def clean_combined_data(reddit_df, youtube_df):\n",
    "    \"\"\"Clean and combine Reddit and YouTube data.\"\"\"\n",
    "    \n",
    "    # Standardize Reddit data\n",
    "    reddit_clean = reddit_df.copy()\n",
    "    reddit_clean['text'] = reddit_clean['body']\n",
    "    reddit_clean['date'] = pd.to_datetime(reddit_clean['created_utc'])\n",
    "    reddit_clean['platform'] = 'reddit'\n",
    "    reddit_clean['community'] = reddit_clean['subreddit']\n",
    "    \n",
    "    # Standardize YouTube data\n",
    "    youtube_clean = youtube_df.copy()\n",
    "    youtube_clean['date'] = pd.to_datetime(youtube_clean['published_at'])\n",
    "    youtube_clean['platform'] = 'youtube'\n",
    "    youtube_clean['community'] = youtube_clean['channel_title']\n",
    "    youtube_clean['category'] = youtube_clean['influencer_category']\n",
    "    \n",
    "    # Select common columns\n",
    "    common_columns = ['text', 'date', 'platform', 'community', 'category', 'true_misogyny']\n",
    "    \n",
    "    reddit_standardized = reddit_clean[common_columns + ['score']].copy()\n",
    "    youtube_standardized = youtube_clean[common_columns + ['like_count']].copy()\n",
    "    \n",
    "    # Add missing columns with defaults\n",
    "    reddit_standardized['like_count'] = reddit_standardized['score']\n",
    "    youtube_standardized['score'] = youtube_standardized['like_count']\n",
    "    \n",
    "    # Combine datasets\n",
    "    combined_data = pd.concat([\n",
    "        reddit_standardized[common_columns + ['score']], \n",
    "        youtube_standardized[common_columns + ['score']]\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    return combined_data\n",
    "\n",
    "# Clean the data\n",
    "print(\"üßπ Cleaning and combining data...\")\n",
    "combined_data = clean_combined_data(reddit_data, youtube_data)\n",
    "\n",
    "# Basic cleaning using our TextProcessor\n",
    "print(\"üî§ Processing text...\")\n",
    "combined_data['text_length'] = combined_data['text'].str.len()\n",
    "combined_data['word_count'] = combined_data['text'].str.split().str.len()\n",
    "\n",
    "# Filter by text length (remove very short/long texts)\n",
    "min_length, max_length = 10, 500\n",
    "initial_count = len(combined_data)\n",
    "combined_data = combined_data[\n",
    "    (combined_data['text_length'] >= min_length) & \n",
    "    (combined_data['text_length'] <= max_length)\n",
    "]\n",
    "filtered_count = len(combined_data)\n",
    "\n",
    "print(f\"üìä Data after cleaning:\")\n",
    "print(f\"   Total comments: {filtered_count:,} (removed {initial_count - filtered_count:,})\")\n",
    "print(f\"   Reddit: {len(combined_data[combined_data['platform'] == 'reddit']):,}\")\n",
    "print(f\"   YouTube: {len(combined_data[combined_data['platform'] == 'youtube']):,}\")\n",
    "print(f\"   Date range: {combined_data['date'].min()} to {combined_data['date'].max()}\")\n",
    "print(f\"   Average text length: {combined_data['text_length'].mean():.1f} characters\")\n",
    "\n",
    "# Show distribution by platform and category\n",
    "print(\"\\nüìà Distribution by Platform and Category:\")\n",
    "platform_category_dist = combined_data.groupby(['platform', 'category']).agg({\n",
    "    'text': 'count',\n",
    "    'true_misogyny': 'mean'\n",
    "}).round(3)\n",
    "platform_category_dist.columns = ['comment_count', 'misogyny_rate']\n",
    "print(platform_category_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32fdd16",
   "metadata": {},
   "source": [
    "## 5. Curate and Load Misogynistic Lexicon\n",
    "\n",
    "We'll create a comprehensive lexicon of misogynistic terms for detection. This includes:\n",
    "- General derogatory terms for women\n",
    "- Red-pill/manosphere specific terminology\n",
    "- Incel community language\n",
    "- MGTOW (Men Going Their Own Way) terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive misogyny lexicon\n",
    "misogyny_lexicon = create_misogyny_lexicon()\n",
    "\n",
    "# Add additional terms specific to our research\n",
    "additional_terms = {\n",
    "    # Andrew Tate specific terms\n",
    "    'matrix', 'escape the matrix', 'top g', 'war room',\n",
    "    \n",
    "    # Red-pill economics\n",
    "    'smv', 'sexual market value', 'wall hitting', 'post wall',\n",
    "    'branch swinging', 'monkey branching',\n",
    "    \n",
    "    # Additional derogatory terms\n",
    "    'basic bitch', 'karen', 'simp', 'white knight',\n",
    "    'virtue signaling', 'blue pill', 'red pill',\n",
    "    \n",
    "    # Phrases indicating misogynistic thinking\n",
    "    'women logic', 'female logic', 'female privilege',\n",
    "    'pussy pass', 'women and children first'\n",
    "}\n",
    "\n",
    "# Combine lexicons\n",
    "extended_lexicon = misogyny_lexicon.union(additional_terms)\n",
    "\n",
    "print(f\"üìñ Misogyny Lexicon Statistics:\")\n",
    "print(f\"   Base terms: {len(misogyny_lexicon)}\")\n",
    "print(f\"   Additional terms: {len(additional_terms)}\")\n",
    "print(f\"   Total terms: {len(extended_lexicon)}\")\n",
    "\n",
    "# Display sample terms by category\n",
    "print(\"\\nüîç Sample Terms by Category:\")\n",
    "\n",
    "categories = {\n",
    "    'Derogatory terms': ['bitch', 'slut', 'whore', 'thot', 'skank'],\n",
    "    'Red-pill terms': ['hypergamy', 'awalt', 'chad', 'beta', 'alpha'],\n",
    "    'Incel terms': ['femoid', 'foid', 'roastie', 'becky', 'stacy'],\n",
    "    'MGTOW terms': ['gynocentrism', 'simp', 'white knight', 'pussy pass'],\n",
    "    'Phrases': ['women logic', 'female privilege', 'escape the matrix']\n",
    "}\n",
    "\n",
    "for category, terms in categories.items():\n",
    "    available_terms = [term for term in terms if term in extended_lexicon]\n",
    "    print(f\"   {category}: {available_terms[:5]}\")\n",
    "\n",
    "# Test lexicon on sample texts\n",
    "test_texts = [\n",
    "    \"women are hypergamous by nature\",\n",
    "    \"typical female behavior right there\",\n",
    "    \"she's just another basic bitch seeking attention\",\n",
    "    \"this is a normal discussion about gender\",\n",
    "    \"Andrew Tate speaks the truth about the matrix\"\n",
    "]\n",
    "\n",
    "print(\"\\nüß™ Lexicon Testing:\")\n",
    "for text in test_texts:\n",
    "    matching_terms = [term for term in extended_lexicon if term.lower() in text.lower()]\n",
    "    print(f\"   '{text[:40]}...' ‚Üí {len(matching_terms)} terms: {matching_terms[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f26ed",
   "metadata": {},
   "source": [
    "## 6. Misogyny Detection: Hybrid Approach\n",
    "\n",
    "We'll use our hybrid misogyny detection system that combines:\n",
    "1. **Lexicon-based detection**: Pattern matching with our curated terms\n",
    "2. **Machine learning classification**: Trained classifier for context understanding\n",
    "\n",
    "This approach provides both precision (lexicon) and recall (ML model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the misogyny detection model\n",
    "print(\"ü§ñ Training Misogyny Detection Model...\")\n",
    "\n",
    "# Create training data (combining synthetic labeled data with our ground truth)\n",
    "training_data = create_synthetic_training_data()\n",
    "\n",
    "# Add some examples from our actual data for more realistic training\n",
    "sample_data = combined_data.sample(200, random_state=42)\n",
    "additional_training = pd.DataFrame({\n",
    "    'text': sample_data['text'],\n",
    "    'is_misogynistic': sample_data['true_misogyny'].astype(int)\n",
    "})\n",
    "\n",
    "# Combine training datasets\n",
    "full_training_data = pd.concat([training_data, additional_training], ignore_index=True)\n",
    "print(f\"üìö Training data: {len(full_training_data)} examples\")\n",
    "print(f\"   Positive examples: {full_training_data['is_misogynistic'].sum()}\")\n",
    "print(f\"   Negative examples: {(full_training_data['is_misogynistic'] == 0).sum()}\")\n",
    "\n",
    "# Train the model\n",
    "training_results = misogyny_detector.train_classifier(full_training_data)\n",
    "\n",
    "print(\"‚úÖ Model Training Complete!\")\n",
    "print(f\"   Training Accuracy: {training_results['train_accuracy']:.3f}\")\n",
    "print(f\"   Test Accuracy: {training_results['test_accuracy']:.3f}\")\n",
    "print(f\"   Cross-validation: {training_results['cv_mean']:.3f} ¬± {training_results['cv_std']:.3f}\")\n",
    "\n",
    "# Apply detection to our full dataset\n",
    "print(\"\\nüîç Applying Misogyny Detection to Full Dataset...\")\n",
    "detection_results = misogyny_detector.analyze_dataset(combined_data, 'text')\n",
    "\n",
    "print(f\"üìä Detection Results:\")\n",
    "print(f\"   Detected misogynistic comments: {detection_results['is_misogynistic'].sum():,}\")\n",
    "print(f\"   Detection rate: {detection_results['is_misogynistic'].mean():.3f}\")\n",
    "print(f\"   Average confidence: {detection_results['confidence'].mean():.3f}\")\n",
    "\n",
    "# Compare with ground truth for validation\n",
    "if 'true_misogyny' in detection_results.columns:\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    y_true = detection_results['true_misogyny']\n",
    "    y_pred = detection_results['is_misogynistic']\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Validation Against Ground Truth:\")\n",
    "    print(f\"   Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"   Precision: {precision:.3f}\")\n",
    "    print(f\"   Recall: {recall:.3f}\")\n",
    "    print(f\"   F1-Score: {f1:.3f}\")\n",
    "\n",
    "# Show examples of detected misogyny\n",
    "print(\"\\nüìã Sample Detected Misogynistic Comments:\")\n",
    "misogynistic_samples = detection_results[detection_results['is_misogynistic']].nlargest(5, 'confidence')\n",
    "for idx, row in misogynistic_samples.iterrows():\n",
    "    print(f\"   Platform: {row['platform']}, Confidence: {row['confidence']:.3f}\")\n",
    "    print(f\"   Text: {row['text'][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad534ae9",
   "metadata": {},
   "source": [
    "## 7. Time Series Analysis: Tracking Trends Over Time\n",
    "\n",
    "Now we'll analyze how misogynistic content has changed over time and correlate it with key events in the red-pill influencer timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare time series data\n",
    "print(\"üìà Preparing Time Series Analysis...\")\n",
    "\n",
    "# Create time series aggregation\n",
    "time_series_data = time_series_analyzer.prepare_time_series(\n",
    "    detection_results, \n",
    "    date_column='date',\n",
    "    misogyny_column='is_misogynistic',\n",
    "    community_column='platform'\n",
    ")\n",
    "\n",
    "print(f\"üìä Time Series Data:\")\n",
    "print(f\"   Data points: {len(time_series_data)}\")\n",
    "print(f\"   Date range: {time_series_data['date'].min()} to {time_series_data['date'].max()}\")\n",
    "print(f\"   Platforms: {time_series_data['platform'].unique() if 'platform' in time_series_data.columns else 'Combined'}\")\n",
    "\n",
    "# Calculate overall trend\n",
    "overall_trend = time_series_analyzer.calculate_trend(time_series_data)\n",
    "\n",
    "print(f\"\\nüìà Overall Trend Analysis:\")\n",
    "print(f\"   Direction: {overall_trend['trend_direction']}\")\n",
    "print(f\"   Slope: {overall_trend['slope']:.6f}\")\n",
    "print(f\"   R-squared: {overall_trend['r_squared']:.3f}\")\n",
    "print(f\"   Statistical significance: {'Yes' if overall_trend['is_significant'] else 'No'} (p={overall_trend['p_value']:.3f})\")\n",
    "print(f\"   Percentage change: {overall_trend['percentage_change']:.1f}%\")\n",
    "\n",
    "# Analyze event correlations\n",
    "print(f\"\\nüéØ Analyzing Event Correlations...\")\n",
    "event_correlation = time_series_analyzer.analyze_event_correlation(time_series_data)\n",
    "\n",
    "print(f\"üìÖ Event Correlation Results:\")\n",
    "print(f\"   Total events analyzed: {len(event_correlation)}\")\n",
    "\n",
    "# Show significant events\n",
    "significant_events = event_correlation[event_correlation['is_significant']]\n",
    "if len(significant_events) > 0:\n",
    "    print(f\"   Significant correlations: {len(significant_events)}\")\n",
    "    print(f\"\\nüîç Top Significant Event Impacts:\")\n",
    "    top_events = significant_events.nlargest(3, 'effect_size')\n",
    "    for _, event in top_events.iterrows():\n",
    "        print(f\"   ‚Ä¢ {event['event'][:60]}...\")\n",
    "        print(f\"     Date: {event['event_date'].strftime('%Y-%m-%d')}\")\n",
    "        print(f\"     Change: {event['percent_change']:+.1f}%\")\n",
    "        print(f\"     P-value: {event['p_value']:.3f}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"   No statistically significant event correlations found\")\n",
    "\n",
    "# Compare platforms\n",
    "if 'platform' in detection_results.columns:\n",
    "    print(f\"\\nüèõÔ∏è Platform Comparison Analysis...\")\n",
    "    platform_comparison = time_series_analyzer.compare_communities(\n",
    "        detection_results,\n",
    "        community_column='platform',\n",
    "        date_column='date',\n",
    "        misogyny_column='is_misogynistic'\n",
    "    )\n",
    "    \n",
    "    print(\"üìä Platform Comparison Results:\")\n",
    "    for _, platform in platform_comparison.iterrows():\n",
    "        print(f\"   {platform['community']}:\")\n",
    "        print(f\"     Misogyny rate: {platform['misogyny_rate']:.3f}\")\n",
    "        print(f\"     Trend: {platform['trend_direction']}\")\n",
    "        print(f\"     Comments: {platform['total_comments']:,}\")\n",
    "\n",
    "# Display time series data sample\n",
    "print(f\"\\nüìã Sample Time Series Data:\")\n",
    "print(time_series_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e530d5",
   "metadata": {},
   "source": [
    "## 8. Visualization: Creating Interactive Charts and Dashboards\n",
    "\n",
    "Let's create comprehensive visualizations to illustrate our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea411fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "print(\"üìä Creating Visualizations...\")\n",
    "\n",
    "# 1. Time Series Plot with Events\n",
    "print(\"   Creating time series plot...\")\n",
    "ts_fig = visualizer.plot_time_series(\n",
    "    time_series_data,\n",
    "    value_column='normalized_misogyny',\n",
    "    title='Misogyny Trends Over Time with Key Events',\n",
    "    include_events=True\n",
    ")\n",
    "ts_fig.show()\n",
    "\n",
    "# 2. Platform/Community Comparison\n",
    "if len(platform_comparison) > 0:\n",
    "    print(\"   Creating platform comparison plot...\")\n",
    "    platform_fig = visualizer.plot_community_comparison(\n",
    "        platform_comparison,\n",
    "        title='Misogyny Rates by Platform'\n",
    "    )\n",
    "    platform_fig.show()\n",
    "\n",
    "# 3. Event Correlation Analysis\n",
    "if len(event_correlation) > 0:\n",
    "    print(\"   Creating event correlation plot...\")\n",
    "    event_fig = visualizer.plot_event_correlation(\n",
    "        event_correlation,\n",
    "        title='Impact of Key Events on Misogynistic Content'\n",
    "    )\n",
    "    event_fig.show()\n",
    "\n",
    "# 4. Word Frequency Analysis\n",
    "print(\"   Analyzing most common misogynistic terms...\")\n",
    "misogyny_patterns = misogyny_detector.get_misogynistic_patterns(\n",
    "    detection_results, \n",
    "    text_column='text'\n",
    ")\n",
    "\n",
    "if misogyny_patterns['most_common_words']:\n",
    "    word_freq_fig = visualizer.plot_word_frequency(\n",
    "        misogyny_patterns['most_common_words'],\n",
    "        title='Most Common Words in Misogynistic Comments'\n",
    "    )\n",
    "    word_freq_fig.show()\n",
    "\n",
    "# 5. Comprehensive Dashboard\n",
    "print(\"   Creating comprehensive dashboard...\")\n",
    "dashboard_fig = visualizer.create_dashboard(\n",
    "    time_series_data,\n",
    "    platform_comparison if len(platform_comparison) > 0 else None,\n",
    "    event_correlation if len(event_correlation) > 0 else None,\n",
    "    misogyny_patterns['most_common_words']\n",
    ")\n",
    "dashboard_fig.show()\n",
    "\n",
    "# Display key statistics\n",
    "print(f\"\\nüìà Key Visualization Insights:\")\n",
    "print(f\"   üìä Total data points visualized: {len(time_series_data):,}\")\n",
    "print(f\"   üìÖ Analysis period: {time_series_data['date'].min().strftime('%Y-%m-%d')} to {time_series_data['date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"   üéØ Events with significant impact: {len(significant_events) if len(significant_events) > 0 else 0}\")\n",
    "print(f\"   üèõÔ∏è Platforms analyzed: {len(platform_comparison) if len(platform_comparison) > 0 else 1}\")\n",
    "print(f\"   üî§ Most common misogynistic terms: {len(misogyny_patterns['most_common_words'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839d6ee",
   "metadata": {},
   "source": [
    "## 9. Final Analysis and Conclusions\n",
    "\n",
    "Let's summarize our findings and generate a comprehensive report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa864816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive final report\n",
    "print(\"üìã Generating Final Analysis Report...\")\n",
    "\n",
    "# Generate summary report\n",
    "summary_report = time_series_analyzer.generate_summary_report(\n",
    "    time_series_data,\n",
    "    platform_comparison if len(platform_comparison) > 0 else None,\n",
    "    event_correlation if len(event_correlation) > 0 else None\n",
    ")\n",
    "\n",
    "print(summary_report)\n",
    "\n",
    "# Answer our core research questions\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ ANSWERS TO CORE RESEARCH QUESTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ HAS MISOGYNISTIC LANGUAGE INCREASED OVER TIME?\")\n",
    "if overall_trend['trend_direction'] == 'increasing':\n",
    "    print(f\"   ‚úÖ YES - There is an {overall_trend['trend_direction']} trend\")\n",
    "    print(f\"   üìà Slope: {overall_trend['slope']:.6f}\")\n",
    "    print(f\"   üìä Percentage change: {overall_trend['percentage_change']:+.1f}%\")\n",
    "    print(f\"   üéØ Statistical significance: {'Strong' if overall_trend['is_significant'] else 'Weak'}\")\n",
    "else:\n",
    "    print(f\"   ‚ùå NO - The trend is {overall_trend['trend_direction']}\")\n",
    "    print(f\"   üìà Percentage change: {overall_trend['percentage_change']:+.1f}%\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ IS THERE CORRELATION WITH RED-PILL INFLUENCER EVENTS?\")\n",
    "if len(significant_events) > 0:\n",
    "    print(f\"   ‚úÖ YES - Found {len(significant_events)} significant correlations\")\n",
    "    print(\"   üîç Key impactful events:\")\n",
    "    for _, event in significant_events.head(3).iterrows():\n",
    "        print(f\"      ‚Ä¢ {event['event'][:50]}... ({event['percent_change']:+.1f}% change)\")\n",
    "else:\n",
    "    print(\"   ‚ùå NO - No statistically significant correlations found\")\n",
    "    print(\"   üìù This could indicate either:\")\n",
    "    print(\"      ‚Ä¢ Events don't significantly impact misogyny levels\")\n",
    "    print(\"      ‚Ä¢ Effects are delayed or indirect\")\n",
    "    print(\"      ‚Ä¢ Sample size or time window limitations\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ WHICH COMMUNITIES ARE MOST AFFECTED?\")\n",
    "if len(platform_comparison) > 0:\n",
    "    highest_platform = platform_comparison.iloc[0]\n",
    "    print(f\"   üèÜ Highest misogyny rate: {highest_platform['community']}\")\n",
    "    print(f\"   üìä Rate: {highest_platform['misogyny_rate']:.3f}\")\n",
    "    print(f\"   üìà Trend: {highest_platform['trend_direction']}\")\n",
    "    \n",
    "    print(\"\\n   üìã Full platform ranking:\")\n",
    "    for i, (_, platform) in enumerate(platform_comparison.iterrows(), 1):\n",
    "        print(f\"      {i}. {platform['community']}: {platform['misogyny_rate']:.3f} rate \"\n",
    "              f\"({platform['trend_direction']} trend)\")\n",
    "\n",
    "# Additional insights\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí° ADDITIONAL INSIGHTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä DETECTION MODEL PERFORMANCE:\")\n",
    "print(f\"   üéØ Accuracy: {accuracy:.3f}\")\n",
    "print(f\"   üéØ Precision: {precision:.3f}\")\n",
    "print(f\"   üéØ Recall: {recall:.3f}\")\n",
    "print(f\"   üéØ F1-Score: {f1:.3f}\")\n",
    "\n",
    "print(f\"\\nüî§ LEXICON ANALYSIS:\")\n",
    "print(f\"   üìñ Terms in lexicon: {len(extended_lexicon)}\")\n",
    "print(f\"   üéØ Most common misogynistic terms found:\")\n",
    "for term, count in list(misogyny_patterns['most_common_lexicon_terms'].items())[:5]:\n",
    "    print(f\"      ‚Ä¢ '{term}': {count} occurrences\")\n",
    "\n",
    "print(f\"\\nüìà DATA VOLUME:\")\n",
    "print(f\"   üí¨ Total comments analyzed: {len(detection_results):,}\")\n",
    "print(f\"   üö® Misogynistic comments detected: {detection_results['is_misogynistic'].sum():,}\")\n",
    "print(f\"   üìä Overall misogyny rate: {detection_results['is_misogynistic'].mean():.3f}\")\n",
    "\n",
    "# Recommendations for stakeholders\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìù RECOMMENDATIONS FOR STAKEHOLDERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "recommendations = [\n",
    "    \"üõ°Ô∏è PLATFORM MODERATION: Focus resources on communities with highest misogyny rates\",\n",
    "    \"üìä CONTINUOUS MONITORING: Implement real-time tracking of misogynistic language trends\",\n",
    "    \"üéØ EVENT-BASED INTERVENTIONS: Prepare response strategies around influencer milestones\",\n",
    "    \"ü§ù COMMUNITY ENGAGEMENT: Develop counter-messaging campaigns in affected communities\",\n",
    "    \"üìö RESEARCH EXPANSION: Extend analysis to more platforms and longer time periods\",\n",
    "    \"üîç GRANULAR ANALYSIS: Investigate specific types of misogynistic language for targeted interventions\"\n",
    "]\n",
    "\n",
    "for recommendation in recommendations:\n",
    "    print(f\"   {recommendation}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìÅ All results and visualizations have been saved to the project directory\")\n",
    "print(f\"üìä Dashboard and plots are ready for presentation\")\n",
    "print(f\"üìã This analysis provides evidence-based insights for policy and intervention decisions\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
